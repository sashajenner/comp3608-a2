\section{Results and Discussion}

\subsection{Classifier Accuracy}
The canonical Na\"ive Bayes (NB)\nomenclature{NB}{Na\"ive Bayes} and Decision Tree (DT)\nomenclature{DT}{Decision Tree} classification algorithms were implemented with tie decisions resulting in a `yes' and are hereafter referred to as MyNB and MyDT respectively. 10-fold stratified cross validation was then performed on these algorithms and 12 other inbuilt Weka algorithms using the dataset described in section \ref{sec:data} after normalisation and discretisation for the numeric and nominal classification algorithms respectively.

Tables \ref{tab:acc:num} and \ref{tab:acc:nom} present all the resulting accuracy figures for each tested classification algorithm, shown in percentage (\%) to 4 d.p., using both the full dataset and the dataset after CFS.

\begin{table}[h!]
    \caption{The 10-fold stratified cross validation accuracy in percentage (\%) of each tested \textit{numeric} classification algorithm using the dataset with and without CFS. \label{tab:acc:num}}
    \begin{center}
    \begin{tabular}{|m{2cm}*{8}{|c}|}
        \hline
        \textbf{Numeric Data} & ZeroR & 1R & 1NN &5NN &NB &MLP &SVM & \color{blue}MyNB \\
        \hline
        No feature selection & 65.1042 &70.8333 &67.8385 &74.4792 &75.1302 &75.3906 &76.3021 &75.2614 \\
        \hline
        CFS & 65.1042 &70.8333 &69.0104 &74.4792 &76.3021 &75.7813&76.6927 & 76.0407 \\
        \hline
    \end{tabular}
    \end{center}
\end{table}

\begin{table}[h!]
    \caption{The 10-fold stratified cross validation accuracy in percentage (\%) of each tested \textit{nominal} classification algorithm using the dataset with and without CFS. \label{tab:acc:nom}}
    \begin{center}
    \begin{tabular}{|m{2cm}*{6}{|c}|}
        \hline
        \textbf{Nominal Data} & DT unpruned &DT pruned &\color{blue}MyDT &Bagg &Boost &RF \\
        \hline
        No feature selection &75.0000 & 75.3906 &73.4484 &74.8698&76.1719&73.1771 \\
        \hline
        CFS & 79.4271 & 79.4271 &78.3869 & 78.5156 & 78.6458 & 78.9063 \\
        \hline
    \end{tabular}
    \end{center}
\end{table}

\subsection{DT Diagrams}
Decision trees were built on the full discretised dataset using three different algorithms: MyDT, and two DT classifiers from Weka (DT unpruned and DT pruned). The two Weka variants were built using J48 (an implementation of the C4.5 algorithm) with default parameters, but differ in that one has been pruned in addition to the other \cite{weka}. The DT diagrams are displayed in Figures \ref{fig:mydt}, \ref{fig:dt_unprune} and \ref{fig:dt_prune}.

% TODO: move this on the same page

\begin{figure}[h!]
    \begin{obeylines}
        \input{DT_unpruned}
    \end{obeylines}
    \caption{The DT diagram of the Weka J48 algorithm \textit{without} pruning and trained on the full discretised dataset.\label{fig:dt_unprune}}
\end{figure}

\begin{figure}[h!]
    \begin{obeylines}
        \input{DT_pruned}
    \end{obeylines}
    \caption{The DT diagram of the Weka J48 algorithm \textit{with} pruning and trained on the full discretised dataset.\label{fig:dt_prune}}
\end{figure}


\subsection{Discussion}
% kinda tempted to change structure? like combine DT diagrams with DT here idk

\subsubsection{Comparison of Classifiers}

% In the discussion, compare the performance of the classifiers, with and without feature selection. Compare your implementations of NB and DT with Weka’s.

The performance of the classifiers largely varied between different algorithms and datasets. 

For the numeric data, there was a large variance in performance between different algorithms, ranging from around 65\% to almost 77\%. 

The best performing algorithm was the SVM, both with and without feature selection, where it achieved an accuracy of 76.9\% and 76.3\% respectively. Both Naive Bayes and MLP were similar in performance, generally within only 1\% of the SVM accuracy. Therefore this difference may not indicate a significant difference in performance, but could instead be due to random noise in the testing \textbf{Validation??} dataset.

On the other hand, the worst performing algorithms were ZeroR, 1R, and 1NN, achieving accuracies between 65\% and 71\%. These simple algorithms were likely not complex enough to capture patterns in the data that other algorithms were able to recognise (i.e. SVM, MLP, NB).


Within the nominal data, 


however all accuracies were between 65\% and 80\%. 

Nominal better? Weird?? Discussion point? maybe for 3.3.5
or is the data being predicted here actually different? if not its probs just overfitting (to noise) or something and thats something to mention.

\subsubsection{Feature Selection}

% Discuss the effect of the feature selection – did CFS select a subset of the original features, and if so, did the selected subset make intuitive sense to you? Was the feature selection beneficial, i.e. did it improve accuracy, or have any other advantages? Why do you think this is the case?

what features did CFS select?

\subsubsection{Decision Trees}

% How does your DT classifier compare with the unpruned and pruned DT generated by Weka? Discuss the role and effect of pruning.

% Comparison between the DT classifiers and discussion of pruning

\subsubsection{Tree-based Classifiers}

% Comparison between the tree-based classifiers

% Compare the accuracy of the tree-based classifiers (DT, Bagging, Boosting and RF).


\subsubsection{?Anything else that we consider important}
% Include anything else that you consider important

